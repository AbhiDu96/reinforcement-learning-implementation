{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randow Walk\n",
    "---\n",
    "## n-step TD Method\n",
    "\n",
    "<img style=\"float\" src=\"rw-game.png\" alt=\"drawing\" width=\"700\"/>\n",
    "\n",
    "In this MRP, all episodes start in the center state, C, then proceed either left or right by one state on each step, with equal probability. Episodes terminate either on the extreme left or the extreme right. When an episode terminates on the right, a reward of +1 occurs; all other rewards are zero.\n",
    "\n",
    "<img style=\"float\" src=\"n-step.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 states (not including the ending state)\n",
    "NUM_STATES = 19\n",
    "START = 9\n",
    "END_0 = 0\n",
    "END_1 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalk:\n",
    "    \n",
    "    def __init__(self, n, start=START, end=False, lr=0.1, gamma=1):\n",
    "        self.actions = [\"left\", \"right\"]\n",
    "        self.state = start  # current state\n",
    "        self.end = end\n",
    "        self.n = n\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.state_actions = []\n",
    "        # init q estimates\n",
    "        self.Q_values = {}\n",
    "        for i in range(NUM_STATES+2):  \n",
    "            self.Q_values[i] = {}\n",
    "            for a in self.actions:\n",
    "                self.Q_values[i][a] = 0\n",
    "                \n",
    "    def chooseAction(self):    \n",
    "        action = np.random.choice(self.actions)\n",
    "        return action \n",
    "    \n",
    "    def takeAction(self, action):\n",
    "        new_state = self.state\n",
    "        if not self.end:\n",
    "            if action == \"left\":\n",
    "                new_state = self.state-1\n",
    "            else:\n",
    "                new_state = self.state+1\n",
    "            \n",
    "            if new_state in [END_0, END_1]:\n",
    "                self.end = True\n",
    "        self.state = new_state\n",
    "        return self.state\n",
    "    \n",
    "    def giveReward(self):\n",
    "        if self.state == END_0:\n",
    "            return -1\n",
    "        if self.state == END_1:\n",
    "            return 1\n",
    "        # other states\n",
    "        return 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = START\n",
    "        self.end = False\n",
    "           \n",
    "    def play(self, rounds=100):\n",
    "        for _ in range(rounds):\n",
    "            self.reset()\n",
    "            t = 0\n",
    "            T = np.inf\n",
    "            action = self.chooseAction()\n",
    "            \n",
    "            actions = [action]\n",
    "            states = [self.state]\n",
    "            rewards = [0]\n",
    "            while True:\n",
    "                if t < T:\n",
    "                    state = self.takeAction(action)  # next state\n",
    "                    reward = self.giveReward()  # next state-reward\n",
    "                    \n",
    "                    states.append(state)\n",
    "                    rewards.append(reward)\n",
    "                    \n",
    "                    if self.end:\n",
    "                        print(\"End at state {} | number of states {}\".format(state, len(states)))\n",
    "                        T = t+1\n",
    "                    else:\n",
    "                        action = self.chooseAction()\n",
    "                        actions.append(action)  # next action\n",
    "                # state tau being updated\n",
    "                tau = t - self.n + 1\n",
    "                if tau >= 0:\n",
    "                    G = 0\n",
    "                    for i in range(tau+1, min(tau+self.n+1, T+1)):\n",
    "                        G += np.power(self.gamma, i-tau-1)*rewards[i]\n",
    "                    if tau+self.n < T:\n",
    "                        state_action = (states[tau+self.n], actions[tau+self.n])\n",
    "                        G += np.power(self.gamma, self.n)*self.Q_values[state_action[0]][state_action[1]]\n",
    "                    # update Q values\n",
    "                    state_action = (states[tau], actions[tau])\n",
    "                    self.Q_values[state_action[0]][state_action[1]] += self.lr*(G-self.Q_values[state_action[0]][state_action[1]])\n",
    "                \n",
    "                if tau == T-1:\n",
    "                    break\n",
    "                \n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End at state 0 | number of states 106\n",
      "End at state 0 | number of states 188\n",
      "End at state 20 | number of states 40\n",
      "End at state 0 | number of states 26\n",
      "End at state 20 | number of states 182\n",
      "End at state 20 | number of states 222\n",
      "End at state 0 | number of states 80\n",
      "End at state 0 | number of states 26\n",
      "End at state 20 | number of states 24\n",
      "End at state 20 | number of states 46\n",
      "End at state 20 | number of states 94\n",
      "End at state 0 | number of states 98\n",
      "End at state 0 | number of states 52\n",
      "End at state 20 | number of states 68\n",
      "End at state 20 | number of states 192\n",
      "End at state 20 | number of states 136\n",
      "End at state 20 | number of states 56\n",
      "End at state 0 | number of states 126\n",
      "End at state 0 | number of states 84\n",
      "End at state 0 | number of states 80\n",
      "End at state 0 | number of states 376\n",
      "End at state 0 | number of states 130\n",
      "End at state 20 | number of states 48\n",
      "End at state 20 | number of states 44\n",
      "End at state 20 | number of states 132\n",
      "End at state 20 | number of states 48\n",
      "End at state 20 | number of states 166\n",
      "End at state 20 | number of states 114\n",
      "End at state 0 | number of states 40\n",
      "End at state 20 | number of states 124\n",
      "End at state 0 | number of states 36\n",
      "End at state 20 | number of states 30\n",
      "End at state 0 | number of states 138\n",
      "End at state 20 | number of states 138\n",
      "End at state 20 | number of states 86\n",
      "End at state 0 | number of states 500\n",
      "End at state 0 | number of states 108\n",
      "End at state 0 | number of states 150\n",
      "End at state 20 | number of states 136\n",
      "End at state 0 | number of states 30\n",
      "End at state 0 | number of states 392\n",
      "End at state 20 | number of states 38\n",
      "End at state 20 | number of states 174\n",
      "End at state 0 | number of states 32\n",
      "End at state 20 | number of states 44\n",
      "End at state 20 | number of states 150\n",
      "End at state 20 | number of states 154\n",
      "End at state 0 | number of states 46\n",
      "End at state 0 | number of states 84\n",
      "End at state 20 | number of states 102\n",
      "End at state 0 | number of states 40\n",
      "End at state 0 | number of states 18\n",
      "End at state 0 | number of states 24\n",
      "End at state 0 | number of states 26\n",
      "End at state 0 | number of states 178\n",
      "End at state 0 | number of states 98\n",
      "End at state 0 | number of states 58\n",
      "End at state 0 | number of states 78\n",
      "End at state 20 | number of states 196\n",
      "End at state 0 | number of states 14\n",
      "End at state 0 | number of states 22\n",
      "End at state 0 | number of states 208\n",
      "End at state 0 | number of states 156\n",
      "End at state 20 | number of states 98\n",
      "End at state 0 | number of states 100\n",
      "End at state 0 | number of states 56\n",
      "End at state 20 | number of states 136\n",
      "End at state 0 | number of states 54\n",
      "End at state 0 | number of states 82\n",
      "End at state 0 | number of states 30\n",
      "End at state 20 | number of states 48\n",
      "End at state 0 | number of states 190\n",
      "End at state 0 | number of states 100\n",
      "End at state 0 | number of states 18\n",
      "End at state 20 | number of states 274\n",
      "End at state 20 | number of states 48\n",
      "End at state 0 | number of states 64\n",
      "End at state 20 | number of states 164\n",
      "End at state 20 | number of states 178\n",
      "End at state 20 | number of states 48\n",
      "End at state 0 | number of states 488\n",
      "End at state 20 | number of states 46\n",
      "End at state 0 | number of states 82\n",
      "End at state 0 | number of states 106\n",
      "End at state 20 | number of states 84\n",
      "End at state 0 | number of states 30\n",
      "End at state 20 | number of states 66\n",
      "End at state 0 | number of states 68\n",
      "End at state 0 | number of states 28\n",
      "End at state 0 | number of states 74\n",
      "End at state 0 | number of states 26\n",
      "End at state 0 | number of states 136\n",
      "End at state 20 | number of states 152\n",
      "End at state 0 | number of states 216\n",
      "End at state 0 | number of states 34\n",
      "End at state 0 | number of states 76\n",
      "End at state 20 | number of states 44\n",
      "End at state 20 | number of states 90\n",
      "End at state 0 | number of states 212\n",
      "End at state 20 | number of states 40\n"
     ]
    }
   ],
   "source": [
    "rw = RandomWalk(n=3)\n",
    "rw.play(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'left': 0, 'right': 0},\n",
       " 1: {'left': -0.997534965295042, 'right': -0.7239519692230982},\n",
       " 2: {'left': -0.8392118401720433, 'right': -0.6394526508921221},\n",
       " 3: {'left': -0.7554599294286835, 'right': -0.5419782947847438},\n",
       " 4: {'left': -0.6718963513067013, 'right': -0.5201297882185493},\n",
       " 5: {'left': -0.5782429463877724, 'right': -0.4160937563589277},\n",
       " 6: {'left': -0.4932368848752557, 'right': -0.388801696560297},\n",
       " 7: {'left': -0.43554033317074614, 'right': -0.22944565819591475},\n",
       " 8: {'left': -0.3266028546177513, 'right': -0.14702311616942723},\n",
       " 9: {'left': -0.2906020444017145, 'right': -0.07640697619864936},\n",
       " 10: {'left': -0.22761135053524775, 'right': -0.033160735652345084},\n",
       " 11: {'left': -0.16659698517527222, 'right': 0.03302730515835058},\n",
       " 12: {'left': -0.06489122906030385, 'right': 0.17646238703182698},\n",
       " 13: {'left': 0.0605155055503486, 'right': 0.28393965128880116},\n",
       " 14: {'left': 0.13247040692234296, 'right': 0.42325915736689446},\n",
       " 15: {'left': 0.2604776914779341, 'right': 0.5177046328135734},\n",
       " 16: {'left': 0.3587788590502488, 'right': 0.6183025801243828},\n",
       " 17: {'left': 0.4475686136053967, 'right': 0.7877171006395876},\n",
       " 18: {'left': 0.627753798101353, 'right': 0.8929709211202069},\n",
       " 19: {'left': 0.717346999531305, 'right': 0.9892247363356941},\n",
       " 20: {'left': 0, 'right': 0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw.Q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0. ,\n",
       "        0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-20, 22, 2) / 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.88888889, -0.77777778, -0.66666667, -0.55555556,\n",
       "       -0.44444444, -0.33333333, -0.22222222, -0.11111111,  0.        ,\n",
       "        0.11111111,  0.22222222,  0.33333333,  0.44444444,  0.55555556,\n",
       "        0.66666667,  0.77777778,  0.88888889,  1.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-18, 20, 2) / 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
