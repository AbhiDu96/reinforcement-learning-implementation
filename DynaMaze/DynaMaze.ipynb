{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "---\n",
    "<img style=\"float:left\" src=\"Maze.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "> Consider the simple maze shown inset in the Figure. In each of the 47 states there are four actions, `up`, `down`, `right`, and `left`, which take the agent deterministically to the corresponding neighboring states, except when movement is blocked by an obstacle or the edge of the maze, in which case the agent remains where it is. Reward is zero on all transitions, except those into the goal state, on which it is +1. After reaching the goal state `(G)`, the agent returns to the start state `(S)` to begin a new episode. This is a discounted, episodic task with `gamma = 0.95`.\n",
    "---\n",
    ">\n",
    "## Dyna-Q\n",
    "\n",
    "---\n",
    "<img style=\"float:left\" src=\"Tabular_Dyna-Q.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 6\n",
    "COLS = 9\n",
    "S = (2, 0)\n",
    "G = (0, 8)\n",
    "BLOCKS = [(1, 2), (2, 2), (3, 2), (0, 7), (1, 7), (2, 7), (4, 5)]\n",
    "ACTIONS = [\"left\", \"up\", \"right\", \"down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rows = ROWS\n",
    "        self.cols = COLS\n",
    "        self.start = S\n",
    "        self.goal = G\n",
    "        self.blocks = BLOCKS\n",
    "        self.state = S\n",
    "        self.end = False\n",
    "        # init maze\n",
    "        self.maze = np.zeros((self.rows, self.cols))\n",
    "        for b in self.blocks:\n",
    "            self.maze[b] = -1\n",
    "            \n",
    "    def nxtPosition(self, action):\n",
    "        r, c = self.state\n",
    "        if action == \"left\":\n",
    "            c -= 1\n",
    "        elif action == \"right\":\n",
    "            c += 1\n",
    "        elif action == \"up\":\n",
    "            r -= 1\n",
    "        else:\n",
    "            r += 1\n",
    "        \n",
    "        if (r >= 0 and r <= self.rows-1) and (c >= 0 and c <= self.cols-1):\n",
    "            if (r, c) not in self.blocks:\n",
    "                self.state = (r, c)\n",
    "        return self.state\n",
    "    \n",
    "    def giveReward(self):\n",
    "        if self.state == self.goal:\n",
    "            self.end = True\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def showMaze(self):\n",
    "        self.maze[self.state] = 1\n",
    "        for i in range(0, self.rows):\n",
    "            print('-------------------------------------')\n",
    "            out = '| '\n",
    "            for j in range(0, self.cols):\n",
    "                if self.maze[i, j] == 1:\n",
    "                    token = '*'\n",
    "                if self.maze[i, j] == -1:\n",
    "                    token = 'z'\n",
    "                if self.maze[i, j] == 0:\n",
    "                    token = '0'\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | z | 0 | \n",
      "-------------------------------------\n",
      "| 0 | 0 | z | 0 | 0 | 0 | 0 | z | 0 | \n",
      "-------------------------------------\n",
      "| * | 0 | z | 0 | 0 | 0 | 0 | z | 0 | \n",
      "-------------------------------------\n",
      "| 0 | 0 | z | 0 | 0 | 0 | 0 | 0 | 0 | \n",
      "-------------------------------------\n",
      "| 0 | 0 | 0 | 0 | 0 | z | 0 | 0 | 0 | \n",
      "-------------------------------------\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | \n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m = Maze()\n",
    "m.showMaze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynaAgent:\n",
    "    \n",
    "    def __init__(self, exp_rate=0.3, lr=0.1, n_steps=5):\n",
    "        self.maze = Maze()\n",
    "        self.state = S\n",
    "        self.actions = ACTIONS\n",
    "        self.state_actions = []  # state & action track\n",
    "        self.steps = n_steps\n",
    "        \n",
    "        self.Q_values = {}\n",
    "        # model function\n",
    "        self.model = {}\n",
    "        for row in range(ROWS):\n",
    "            for col in range(COLS):\n",
    "                self.Q_values[(row, col)] = {}\n",
    "                self.model[(row, col)] = {}\n",
    "                for a in self.actions:\n",
    "                    self.Q_values[(row, col)][a] = 0\n",
    "                    self.model[(row, col)][a] = (0, (0, 0))  # reward & next state\n",
    "        \n",
    "    def chooseAction(self):\n",
    "        # epsilon-greedy\n",
    "        mx_nxt_reward = -999\n",
    "        action = \"\"\n",
    "        \n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # greedy action\n",
    "            current_position = self.state\n",
    "            # if all actions have same value, then select randomly\n",
    "            if len(set(self.Q_values[current_position].values)) == 1:\n",
    "                action = np.random.choice(self.actions)\n",
    "            else:\n",
    "                for a in self.actions:\n",
    "                    nxt_reward = self.Q_values[current_position][a]\n",
    "                    if nxt_reward >= mx_nxt_reward:\n",
    "                        action = a\n",
    "                        mx_nxt_reward = nxt_reward\n",
    "        return action\n",
    "    \n",
    "    def reset(self):\n",
    "        self.maze = Maze()\n",
    "        self.state = S\n",
    "        self.actions = ACTIONS\n",
    "        self.state_actions = []\n",
    "    \n",
    "    def play(self):\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "        while not self.maze.end:\n",
    "            \n",
    "            action = self.chooseAction()\n",
    "            self.state_actions.append((self.state, action))\n",
    "            \n",
    "            nxtState = self.maze.nxtPosition(action)\n",
    "            reward = self.maze.giveReward()\n",
    "            # update Q-value\n",
    "            self.Q_values[self.state][action] += self.lr*(reward + np.max(self.Q_values[nxtState].values) - self.Q_values[self.state][action])\n",
    "            \n",
    "            # update model\n",
    "            self.model[self.state][action] = (reward, nxtState)\n",
    "            self.state = nxtState\n",
    "            \n",
    "            # loop n times to randomly update Q-value\n",
    "            for _ in range(self.steps):\n",
    "                _state, _action = np.random.choice(self.state_actions)\n",
    "                _reward, _nxtState = self.model[_state][_action]\n",
    "                \n",
    "                self.Q_values[_state][_action] += self.lr*(_reward + np.max(self.Q_values[_nxtState].values) - self.Q_values[_nxtState][_action])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
