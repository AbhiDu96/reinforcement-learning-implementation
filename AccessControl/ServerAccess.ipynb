{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access-Control Queuing Task\n",
    "---\n",
    "This is a decision task involving access control to a set of 10 servers. Customers of four different priorities arrive at a single queue. If given access to a server, the customers pay a reward of `1, 2, 4, or 8` to the server, depending on their priority, with higher priority customers paying more. In each time step, the customer at the head of the queue is either accepted (assigned to one of the servers) or rejected (removed from the queue, with a reward of zero). In either case, on the next time step the next customer in the queue is considered. The queue never empties, and the priorities of the customers in the queue are equally randomly distributed. Of course a customer cannot be served if there is no free server; the customer is always rejected in this case. Each busy server becomes free with probability `p = 0.06` on each time step.\n",
    "\n",
    "The task is to decide on each step whether to accept or reject the next customer, on the basis of his priority and the number of free servers, so as `to maximize long-term reward without discounting`.\n",
    "\n",
    "- State(num_servers, priority)\n",
    "- Action(1, 0)\n",
    "- Reward(1, 2, 4, 8)\n",
    "---\n",
    "<img src=\"differential_sarsa.png\" width=\"600\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from TileCoding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible priorities\n",
    "PRIORITIES = np.arange(0, 4)\n",
    "# reward for each priority\n",
    "REWARDS = np.power(2, np.arange(0, 4))\n",
    "\n",
    "# possible actions\n",
    "REJECT = 0\n",
    "ACCEPT = 1\n",
    "ACTIONS = [REJECT, ACCEPT]\n",
    "\n",
    "# total number of servers\n",
    "NUM_OF_SERVERS = 10\n",
    "\n",
    "# at each time step, a busy server will be free w.p. 0.06\n",
    "PROBABILITY_FREE = 0.06\n",
    "\n",
    "# step size for learning state-action value\n",
    "ALPHA = 0.01\n",
    "\n",
    "# step size for learning average reward\n",
    "BETA = 0.01\n",
    "\n",
    "# probability for exploration\n",
    "EPSILON = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueFunction:\n",
    "    # In this example I use the tiling software instead of implementing standard tiling by myself\n",
    "    # One important thing is that tiling is only a map from (state, action) to a series of indices\n",
    "    # It doesn't matter whether the indices have meaning, only if this map satisfy some property\n",
    "    # View the following webpage for more information\n",
    "    # http://incompleteideas.net/sutton/tiles/tiles3.html\n",
    "    # @alpha: step size for learning state-action value\n",
    "    # @beta: step size for learning average reward\n",
    "    def __init__(self, numOfTilings, alpha=ALPHA, beta=BETA):\n",
    "        self.numOfTilings = numOfTilings\n",
    "        self.maxSize = 2048\n",
    "        self.hashTable = IHT(self.maxSize)\n",
    "        self.weights = np.zeros(self.maxSize)\n",
    "\n",
    "        # state features needs scaling to satisfy the tile software\n",
    "        self.serverScale = self.numOfTilings / float(NUM_OF_SERVERS)\n",
    "        self.priorityScale = self.numOfTilings / float(len(PRIORITIES) - 1)\n",
    "\n",
    "        self.averageReward = 0.0\n",
    "\n",
    "        # divide step size equally to each tiling\n",
    "        self.alpha = alpha / self.numOfTilings\n",
    "\n",
    "        self.beta = beta\n",
    "\n",
    "    # get indices of active tiles for given state and action\n",
    "    def getActiveTiles(self, freeServers, priority, action):\n",
    "        activeTiles = tiles(self.hashTable, self.numOfTilings,\n",
    "                            [self.serverScale * freeServers, self.priorityScale * priority],\n",
    "                            [action])\n",
    "        return activeTiles\n",
    "\n",
    "    # estimate the value of given state and action without subtracting average\n",
    "    def value(self, freeServers, priority, action):\n",
    "        activeTiles = self.getActiveTiles(freeServers, priority, action)\n",
    "        return np.sum(self.weights[activeTiles])\n",
    "\n",
    "    # estimate the value of given state without subtracting average\n",
    "    def stateValue(self, freeServers, priority):\n",
    "        values = [self.value(freeServers, priority, action) for action in ACTIONS]\n",
    "        # if no free server, can't accept\n",
    "        if freeServers == 0:\n",
    "            return values[REJECT]\n",
    "        return np.max(values)\n",
    "\n",
    "    # learn with given sequence\n",
    "    def learn(self, freeServers, priority, action, newFreeServers, newPriority, newAction, reward):\n",
    "        activeTiles = self.getActiveTiles(freeServers, priority, action)\n",
    "        estimation = np.sum(self.weights[activeTiles])\n",
    "        delta = reward - self.averageReward + self.value(newFreeServers, newPriority, newAction) - estimation\n",
    "        # update average reward\n",
    "        self.averageReward += self.beta * delta\n",
    "        delta *= self.alpha\n",
    "        for activeTile in activeTiles:\n",
    "            self.weights[activeTile] += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf = ValueFunction(3)\n",
    "vf.getActiveTiles(10.3, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueFunction:\n",
    "\n",
    "    def __init__(self, alpha=0.01, numOfTilings=8, maxSize=2048):\n",
    "        self.maxSize = maxSize\n",
    "        self.numOfTilings = numOfTilings\n",
    "\n",
    "        # divide step size equally to each tiling\n",
    "        self.alpha = alpha / numOfTilings  # learning rate for each tile\n",
    "\n",
    "        self.hashTable = IHT(maxSize)\n",
    "\n",
    "        # weight for each tile\n",
    "        self.weights = np.zeros(maxSize)\n",
    "\n",
    "        # position and velocity needs scaling to satisfy the tile software\n",
    "        self.serverScale = self.numOfTilings / 10.0  # 10 servers\n",
    "        self.priorityScale = self.numOfTilings / 3.0  # 4 kinds of priorities\n",
    "\n",
    "    # get indices of active tiles for given state and action\n",
    "    def getActiveTiles(self, n_server, priority, action):\n",
    "        activeTiles = tiles(self.hashTable, self.numOfTilings,\n",
    "                            [self.serverScale * n_server, self.priorityScale * priority],\n",
    "                            [action])\n",
    "        return activeTiles\n",
    "\n",
    "    # estimate the value of given state and action\n",
    "    def value(self, state, action):\n",
    "        n_server, priority = state\n",
    "        activeTiles = self.getActiveTiles(n_server, priority, action)\n",
    "        return np.sum(self.weights[activeTiles])\n",
    "\n",
    "    # learn with given state, action and target\n",
    "    def update(self, state, action, delta):\n",
    "        n_server, priority = state\n",
    "        activeTiles = self.getActiveTiles(n_server, priority, action)\n",
    "        for activeTile in activeTiles:\n",
    "            self.weights[activeTile] += delta*self.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf = ValueFunction()\n",
    "vf.getActiveTiles(7, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerAcess:\n",
    "    def __init__(self, exp_rate=0.3, lr=0.1, beta=0.1, alpha=0.1):\n",
    "        self.n_server = 10\n",
    "        self.free_prob = 0.06\n",
    "        self.priorities = range(4)\n",
    "        self.actions = [0, 1]  # 0: reject; 1: accept\n",
    "        self.state = (0, 0)  # (num_servers, priority)\n",
    "        \n",
    "        self.exp_rate = exp_rate\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def numFreeServers(self):\n",
    "        n = 0\n",
    "        n_free_server = self.state[0]\n",
    "        n_busy_server = self.n_server - n_free_server\n",
    "        for _ in range(n_busy_server):\n",
    "            if np.random.uniform(0, 1) <= 0.06:\n",
    "                n += 1\n",
    "        n_free_server += n\n",
    "        self.state = (n_free_server, self.state[1])\n",
    "        return n_free_server\n",
    "    \n",
    "    def chooseAction(self, valueFunc):\n",
    "        n_free_server = self.numFreeServers()\n",
    "        if n_free_server == 0:\n",
    "            return 0\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            values = {}\n",
    "            for a in self.actions:\n",
    "                v = valueFunc.value(self.state, a)\n",
    "                values[a] = v\n",
    "            action = np.random.choice([k for k, v in values.items() if v == max(values.values())])\n",
    "        return action\n",
    "    \n",
    "    def nxtState(self, action):\n",
    "        if action == 1:\n",
    "            n_free_server = self.state[0] - 1\n",
    "        else:\n",
    "            n_free_server = self.state[0]\n",
    "        priority = np.random.choice(self.priorities)\n",
    "        self.state = (n_free_server, priority)\n",
    "        return self.state\n",
    "    \n",
    "    def giveReward(self, action):\n",
    "        # recieve a reward by taking the action\n",
    "        if action == 1:\n",
    "            priority = self.state[1]\n",
    "            return np.power(2, priority)\n",
    "        return 0\n",
    "    \n",
    "    def run(self, valueFunc, steps=100, debug=False):\n",
    "        # updating average reward estimation along the way\n",
    "        avg_reward = 0\n",
    "        self.state = (10, np.random.choice(self.priorities))\n",
    "        cur_state = self.state\n",
    "        cur_action = self.chooseAction(valueFunc)  # n free server is also updated\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            new_state = self.nxtState(cur_action)\n",
    "            reward = self.giveReward(cur_action)\n",
    "            new_action = self.chooseAction(valueFunc)\n",
    "            \n",
    "            if debug:\n",
    "                print(\"state {} action {} reward {}\".format(cur_state, cur_action, reward))\n",
    "            \n",
    "            delta = reward - avg_reward + valueFunc.value(new_state, new_action) - valueFunc.value(cur_state, cur_action)\n",
    "            avg_reward += self.beta*reward\n",
    "            valueFunc.update(cur_state, cur_action, delta)\n",
    "            \n",
    "            cur_state = new_state\n",
    "            cur_action = new_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state (10, 2) action 1 reward 4\n",
      "state (9, 2) action 0 reward 0\n",
      "state (9, 0) action 0 reward 0\n",
      "state (9, 3) action 1 reward 2\n",
      "state (8, 1) action 0 reward 0\n",
      "state (8, 2) action 0 reward 0\n",
      "state (8, 3) action 0 reward 0\n",
      "state (9, 2) action 0 reward 0\n",
      "state (9, 2) action 0 reward 0\n",
      "state (9, 3) action 1 reward 4\n"
     ]
    }
   ],
   "source": [
    "sa = ServerAcess(exp_rate=1)\n",
    "vf = ValueFunction(8)\n",
    "sa.run(vf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for _ in range(1000):\n",
    "    s = sa.numFreeServers()\n",
    "    l.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([563.,   0., 318.,   0., 101.,   0.,  17.,   0.,   0.,   1.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADe1JREFUeJzt3G2IpeV9x/Hvr64mwaRZH0ZZ9qEjZAmRQlQGKwil1TRVV7K+yILS6iJb9o0tBgvppm9KoC/MmyhCEZYoXds0RmLERSXNsipBiA+7PptN6la2Oqy4m/qQiKTF5N8Xcy0d1tE5s3POHOea7weGc9/Xuebc14343Zt7zjmpKiRJ/fq9cS9AkjRahl6SOmfoJalzhl6SOmfoJalzhl6SOmfoJalzhl6SOmfoJalzq8a9AIAzzzyzJicnx70MSVpW9u/f/8uqmphv3sci9JOTk+zbt2/cy5CkZSXJfw0yz1s3ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktS5j8UnYxdjcseDYzv2oZs3je3YkjQor+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6N1DokxxK8kKSZ5Psa2OnJ9mT5OX2eFobT5LbkhxM8nySC0Z5ApKkj7aQK/o/rarzqmqq7e8A9lbVRmBv2we4HNjYfrYDtw9rsZKkhVvMrZvNwK62vQu4atb4XTXjcWB1kjWLOI4kaREGDX0BP06yP8n2NnZ2Vb0O0B7PauNrgddm/e50G5MkjcGqAeddXFWHk5wF7Eny84+YmznG6gOTZv7B2A6wYcOGAZchSVqoga7oq+pwezwC3AdcCLxx7JZMezzSpk8D62f9+jrg8ByvubOqpqpqamJi4sTPQJL0keYNfZJTk3zm2DbwZeBFYDewtU3bCtzftncD17V331wEvHPsFo8kaekNcuvmbOC+JMfm/1tV/SjJU8A9SbYBrwJb2vyHgCuAg8B7wPVDX7UkaWDzhr6qXgG+OMf4fwOXzjFewA1DWZ0kadH8ZKwkdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnDL0kdc7QS1LnBg59kpOSPJPkgbZ/TpInkryc5PtJTmnjn2j7B9vzk6NZuiRpEAu5or8RODBr/1vALVW1EXgL2NbGtwFvVdXngFvaPEnSmAwU+iTrgE3Ad9p+gEuAH7Qpu4Cr2vbmtk97/tI2X5I0BoNe0d8KfB34Xds/A3i7qt5v+9PA2ra9FngNoD3/TpsvSRqDeUOf5ErgSFXtnz08x9Qa4LnZr7s9yb4k+44ePTrQYiVJCzfIFf3FwFeSHALuZuaWza3A6iSr2px1wOG2PQ2sB2jPfxZ48/gXraqdVTVVVVMTExOLOglJ0oebN/RV9Y2qWldVk8DVwMNV9RfAI8BX27StwP1te3fbpz3/cFV94IpekrQ0FvM++r8DbkpykJl78He08TuAM9r4TcCOxS1RkrQYq+af8v+q6lHg0bb9CnDhHHN+A2wZwtokSUPgJ2MlqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOGXpI6Z+glqXOrxr0ALdzkjgfHduxDN28a27ElnRiv6CWpc4Zekjo3b+iTfDLJk0meS/JSkm+28XOSPJHk5STfT3JKG/9E2z/Ynp8c7SlIkj7KIFf0/wNcUlVfBM4DLktyEfAt4Jaq2gi8BWxr87cBb1XV54Bb2jxJ0pjMG/qa8W7bPbn9FHAJ8IM2vgu4qm1vbvu05y9NkqGtWJK0IAPdo09yUpJngSPAHuA/gber6v02ZRpY27bXAq8BtOffAc6Y4zW3J9mXZN/Ro0cXdxaSpA81UOir6rdVdR6wDrgQ+MJc09rjXFfv9YGBqp1VNVVVUxMTE4OuV5K0QAt6101VvQ08ClwErE5y7H3464DDbXsaWA/Qnv8s8OYwFitJWrhB3nUzkWR12/4U8CXgAPAI8NU2bStwf9ve3fZpzz9cVR+4opckLY1BPhm7BtiV5CRm/mG4p6oeSPIz4O4k/wg8A9zR5t8B/EuSg8xcyV89gnVLkgY0b+ir6nng/DnGX2Hmfv3x478BtgxldZKkRfOTsZLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ2bN/RJ1id5JMmBJC8lubGNn55kT5KX2+NpbTxJbktyMMnzSS4Y9UlIkj7cIFf07wN/W1VfAC4CbkhyLrAD2FtVG4G9bR/gcmBj+9kO3D70VUuSBjZv6Kvq9ap6um3/GjgArAU2A7vatF3AVW17M3BXzXgcWJ1kzdBXLkkayILu0SeZBM4HngDOrqrXYeYfA+CsNm0t8NqsX5tuY8e/1vYk+5LsO3r06MJXLkkayMChT/Jp4F7ga1X1q4+aOsdYfWCgamdVTVXV1MTExKDLkCQt0EChT3IyM5H/blX9sA2/ceyWTHs80sangfWzfn0dcHg4y5UkLdQg77oJcAdwoKq+Peup3cDWtr0VuH/W+HXt3TcXAe8cu8UjSVp6qwaYczFwLfBCkmfb2N8DNwP3JNkGvApsac89BFwBHATeA64f6oolSQsyb+ir6jHmvu8OcOkc8wu4YZHrkiQNiZ+MlaTOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOzRv6JHcmOZLkxVljpyfZk+Tl9nhaG0+S25IcTPJ8kgtGuXhJ0vwGuaL/Z+Cy48Z2AHuraiOwt+0DXA5sbD/bgduHs0xJ0omaN/RV9RPgzeOGNwO72vYu4KpZ43fVjMeB1UnWDGuxkqSFO9F79GdX1esA7fGsNr4WeG3WvOk2Jkkak1VDfr3MMVZzTky2M3N7hw0bNgx5GerN5I4Hx3LcQzdvGstxpWE60Sv6N47dkmmPR9r4NLB+1rx1wOG5XqCqdlbVVFVNTUxMnOAyJEnzOdHQ7wa2tu2twP2zxq9r7765CHjn2C0eSdJ4zHvrJsn3gD8BzkwyDfwDcDNwT5JtwKvAljb9IeAK4CDwHnD9CNYsSVqAeUNfVdd8yFOXzjG3gBsWuyhJ0vD4yVhJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOGXpJ6pyhl6TOrRr3AiTNbXLHg2M57qGbN43luBodr+glqXMjCX2Sy5L8IsnBJDtGcQxJ0mCGHvokJwH/BFwOnAtck+TcYR9HkjSYUVzRXwgcrKpXqup/gbuBzSM4jiRpAKP4Y+xa4LVZ+9PAH43gOJI0FOP6wzcszR+/U1XDfcFkC/DnVfVXbf9a4MKq+pvj5m0HtrfdzwO/OMFDngn88gR/d7nynFcGz3llWMw5/0FVTcw3aRRX9NPA+ln764DDx0+qqp3AzsUeLMm+qppa7OssJ57zyuA5rwxLcc6juEf/FLAxyTlJTgGuBnaP4DiSpAEM/Yq+qt5P8tfAvwMnAXdW1UvDPo4kaTAj+WRsVT0EPDSK157Dom//LEOe88rgOa8MIz/nof8xVpL08eJXIEhS55Z16FfaVy0kuTPJkSQvjnstSyXJ+iSPJDmQ5KUkN457TaOW5JNJnkzyXDvnb457TUshyUlJnknywLjXshSSHEryQpJnk+wb6bGW662b9lUL/wH8GTNv6XwKuKaqfjbWhY1Qkj8G3gXuqqo/HPd6lkKSNcCaqno6yWeA/cBVnf93DnBqVb2b5GTgMeDGqnp8zEsbqSQ3AVPA71fVleNez6glOQRMVdXIPzewnK/oV9xXLVTVT4A3x72OpVRVr1fV023718ABZj593a2a8W7bPbn9LM8rsgElWQdsAr4z7rX0aDmHfq6vWug6ACtdkkngfOCJ8a5k9NptjGeBI8Cequr9nG8Fvg78btwLWUIF/DjJ/vZNASOznEOfOca6vupZyZJ8GrgX+FpV/Wrc6xm1qvptVZ3HzCfLL0zS7a26JFcCR6pq/7jXssQurqoLmPmm3xvardmRWM6hH+irFrT8tfvU9wLfraofjns9S6mq3gYeBS4b81JG6WLgK+2e9d3AJUn+dbxLGr2qOtwejwD3MXM7eiSWc+j9qoUVoP1h8g7gQFV9e9zrWQpJJpKsbtufAr4E/Hy8qxqdqvpGVa2rqklm/j9+uKr+cszLGqkkp7Y3F5DkVODLwMjeTbdsQ19V7wPHvmrhAHBP71+1kOR7wE+BzyeZTrJt3GtaAhcD1zJzlfds+7li3IsasTXAI0meZ+aCZk9VrYi3HK4gZwOPJXkOeBJ4sKp+NKqDLdu3V0qSBrNsr+glSYMx9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUuf8DCJNkD36nIlIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
